<!doctype html>
<html>
<head>
<meta charset="utf-8"> 
<title>Room - SFU</title>
<link rel="stylesheet" href="style.css">
</head>
<body>
<div class="container">
  <h2 id="roomTitle">Room</h2>
  <div id="roomInfo" style="margin-bottom: 15px; color: #666;"></div>
  
  <div>
    <button id="toggleVideo" onclick="toggleVideo()">Video Off</button>
    <button id="toggleAudio" onclick="toggleAudio()">Audio Off</button>
    <button id="quitBtn" onclick="quit()">Leave Room</button>
  </div>
</div>

<div class="container">
  <h3>Your Video</h3>
  <video id="local" autoplay playsinline muted></video>
</div>

<div class="container">
  <h3>Participants</h3>
  <div id="remotes"></div>
</div>

<footer class="footer">
  <p>Follow creator on <a href="http://www.linkedin.com/in/viraj-rathod-058ba4280" target="_blank">LinkedIn</a> and <a href="https://github.com/RathodViraj" target="_blank">GitHub</a></p>
</footer>

<script>
let pc, ws, pendingIce = []
let localStream
let videoTrack, audioTrack
const remoteStreams = new Map()

// Helper to get room details from URL
const urlParams = new URLSearchParams(window.location.search)
const roomId = urlParams.get('room')
const title = urlParams.get('title') || ''
const meetingType = urlParams.get('type') || ''

if (!roomId) {
  alert('No room specified')
  window.location.href = '/index.html'
}

document.getElementById('roomTitle').textContent = title || `Room: ${roomId}`
if (meetingType) {
  document.getElementById('roomInfo').innerHTML = `<span class="room-badge badge-${meetingType}">${meetingType}</span> <span>ID: ${roomId}</span>`
} else {
  document.getElementById('roomInfo').textContent = `Room ID: ${roomId}`
}

window.addEventListener('DOMContentLoaded', () => join(roomId, title, meetingType))

async function join(roomName, title = '', meetingType = '') {
  if (pc && pc.connectionState !== 'closed') return;
  
  // 1. Get User Media
  try {
    localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
    document.getElementById('local').srcObject = localStream
    videoTrack = localStream.getVideoTracks()[0]
    audioTrack = localStream.getAudioTracks()[0]
  } catch (e) {
    console.error("Could not get user media", e)
    return
  }

  // 2. Create PC
  pc = new RTCPeerConnection({
    iceServers: [
      { urls: "stun:stun.relay.metered.ca:80" },
      {
        urls: "turn:global.relay.metered.ca:80",
        username: "08c57540fdb60bd386988d52",
        credential: "Vn+jLmPG9MzlDKpi",
      },
      {
        urls: "turn:global.relay.metered.ca:80?transport=tcp",
        username: "08c57540fdb60bd386988d52",
        credential: "Vn+jLmPG9MzlDKpi",
      },
      {
        urls: "turn:global.relay.metered.ca:443",
        username: "08c57540fdb60bd386988d52",
        credential: "Vn+jLmPG9MzlDKpi",
      },
      {
        urls: "turns:global.relay.metered.ca:443?transport=tcp",
        username: "08c57540fdb60bd386988d52",
        credential: "Vn+jLmPG9MzlDKpi",
      },
    ],
    iceTransportPolicy: "relay"
  })

  // 3. Add Local Tracks
  localStream.getTracks().forEach(t => pc.addTrack(t, localStream))

  // Debug: Log ICE and connection states
  pc.oniceconnectionstatechange = () => {
    console.log("ICE connection state:", pc.iceConnectionState)
  }
  pc.onconnectionstatechange = () => {
    console.log("Connection state:", pc.connectionState)
  }
  pc.onicegatheringstatechange = () => {
    console.log("ICE gathering state:", pc.iceGatheringState)
  }

  // 4. Handle ICE
  pc.onicecandidate = e => {
    if (e.candidate && ws.readyState === WebSocket.OPEN) {
      console.log("Sending ICE candidate:", e.candidate.candidate)
      ws.send(JSON.stringify({type:"ice", candidate:e.candidate}))
    }
  }

  // 5. Handle Incoming Tracks
  pc.ontrack = e => {
    if (!e.streams || e.streams.length === 0) return

    const stream = e.streams[0]
    const peerId = stream.id 
    const kind = e.track.kind
    
    console.log(`Received ${kind} track for peer ${peerId}, stream has ${stream.getTracks().length} tracks`)

    let container = remoteStreams.get(peerId)
    
    if (!container) {
      // Create Peer UI Wrapper
      const wrapper = document.createElement('div')
      wrapper.id = 'peer-' + peerId
      wrapper.className = 'peer-wrapper'
      wrapper.style.cssText = 'display:inline-block; margin:10px; position:relative; transition: all 0.3s ease;'
      
      const video = document.createElement('video')
      video.autoplay = true
      video.playsInline = true
      video.style.cssText = 'width:300px; border:2px solid #ccc; background:#000; border-radius: 8px;'
      video.srcObject = stream
      
      wrapper.appendChild(video)
      document.getElementById('remotes').appendChild(wrapper)
      
      container = { wrapper, video, stream, volume: 0, audioCtx: null, analyser: null }
      remoteStreams.set(peerId, container)
      
      // Force play immediately
      setTimeout(() => {
        video.play().catch(e => console.log("Autoplay blocked:", e))
      }, 100)
    } else {
      // Always update the stream to include new tracks
      console.log(`Updating stream for peer ${peerId}`)
      container.stream = stream
      container.video.srcObject = stream
      
      // Force play again
      setTimeout(() => {
        container.video.play().catch(e => console.log("Autoplay blocked:", e))
      }, 100)
    }

    // Setup audio analysis for audio tracks
    if (kind === 'audio' && !container.analyser) {
      setupAudioAnalysis(stream, container)
    }
  }

  // 6. Connect WebSocket
  const backendBase = "discuss-hkih.onrender.com"
  let wsUrl = `wss://${backendBase}/ws?room=${encodeURIComponent(roomName)}`
  ws = new WebSocket(wsUrl)

  ws.onopen = () => console.log("WebSocket connected")
  
  ws.onmessage = async e => {
    const msg = JSON.parse(e.data)

    if (msg.type === "offer") {
      await pc.setRemoteDescription(msg.sdp)
      const ans = await pc.createAnswer()
      await pc.setLocalDescription(ans)
      ws.send(JSON.stringify({type:"answer", sdp:pc.localDescription}))
      
      pendingIce.forEach(c => pc.addIceCandidate(c))
      pendingIce = []
    }
    else if (msg.type === "ice") {
      if (pc.remoteDescription) pc.addIceCandidate(msg.candidate)
      else pendingIce.push(msg.candidate)
    }
    else if (msg.type === "peer-left") {
      const id = msg.peerId
      const container = remoteStreams.get(id)
      if (container) {
        if (container.audioCtx) {
          container.audioCtx.close()
        }
        container.wrapper.remove()
        remoteStreams.delete(id)
      }
    }
    else if (msg.type === "room-ended") {
      alert(msg.message)
      quit()
    }
  }
}

// --- AUDIO LOGIC ---

function setupAudioAnalysis(stream, container) {
  try {
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    
    // Resume context if suspended
    if (audioCtx.state === 'suspended') {
      audioCtx.resume();
    }
    
    const source = audioCtx.createMediaStreamSource(stream);
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256; 
    source.connect(analyser);

    container.audioCtx = audioCtx;
    container.analyser = analyser;
    
    console.log(`Audio analysis setup for peer ${stream.id}`);
  } catch(e) {
    console.error("Audio analysis failed:", e);
  }
}

// Polling loop for volume (every 100ms)
setInterval(() => {
  remoteStreams.forEach(container => {
    if (!container.analyser) return;
    const data = new Uint8Array(container.analyser.frequencyBinCount);
    container.analyser.getByteFrequencyData(data);
    let sum = 0;
    for(let i=0; i<data.length; i++) sum += data[i];
    container.volume = sum / data.length;
  });
}, 100);

// Sorting loop (every 500ms)
setInterval(() => {
  const peers = Array.from(remoteStreams.values());
  peers.sort((a, b) => b.volume - a.volume);

  peers.forEach((container, index) => {
    if(container.wrapper) {
      container.wrapper.style.order = index;
      if(index === 0 && container.volume > 10) {
        container.video.style.borderColor = "#4CAF50"; // Green border for speaker
      } else {
        container.video.style.borderColor = "#ccc";
      }
    }
  });
}, 500);

function toggleVideo() {
  if (videoTrack) {
    videoTrack.enabled = !videoTrack.enabled
    document.getElementById('toggleVideo').textContent = videoTrack.enabled ? 'Video Off' : 'Video On'
  }
}

function toggleAudio() {
  if (audioTrack) {
    audioTrack.enabled = !audioTrack.enabled
    document.getElementById('toggleAudio').textContent = audioTrack.enabled ? 'Audio Off' : 'Audio On'
  }
}

function quit() {
  if (localStream) localStream.getTracks().forEach(t => t.stop())
  if (pc) pc.close()
  if (ws) ws.close()
  remoteStreams.forEach(container => {
    if (container.audioCtx) container.audioCtx.close()
  })
  window.location.href = '/index.html'
}
</script>
</body>
</html>